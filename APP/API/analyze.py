"""
ë¬¸ì„œ ë¶„ì„ API (3ë‹¨ê³„ ê°œì„  - ì¸ìê°’ ì˜¤ë¥˜ ìˆ˜ì •)

ìˆ˜ì •ì‚¬í•­:
- parse_document í˜¸ì¶œ ì‹œ ì¸ì ê°œìˆ˜ ì˜¤ë¥˜(2ê°œ->1ê°œ) ìˆ˜ì •
"""
from fastapi import APIRouter, HTTPException, BackgroundTasks
import logging
from typing import Optional

from APP.schemas.analyze import AnalyzeRequest, AnalyzeResponse, ActionItem
from APP.db.mock_db import mock_db

# ì„œë¹„ìŠ¤ import
from APP.services.llm_service import is_available as llm_available, generate_json
from APP.services.prompts import (
    detect_document_type,
    get_analysis_prompt,
    DocumentType
)
from APP.services.rag_service import get_rag_system
from APP.services.chunker import SmartChunker, ChunkingConfig

# íŒŒì„œ import
from APP.services.document_parser import parse_document

logger = logging.getLogger(__name__)

router = APIRouter()

# ì²­ì»¤ ì¸ìŠ¤í„´ìŠ¤
_chunker = SmartChunker(ChunkingConfig(
    chunk_size=800,
    chunk_overlap=150,
    preserve_tables=True
))


@router.post("/analyze", response_model=AnalyzeResponse)
async def analyze_document(
    request: AnalyzeRequest,
    background_tasks: BackgroundTasks
):
    """
    ë¬¸ì„œ ë¶„ì„ (AI ë¶„ì„ + RAG ì¸ë±ì‹±)
    """
    document_id = request.document_id
    
    # 1. ë¬¸ì„œ ì¡´ì¬ í™•ì¸
    document = mock_db.get_document(document_id)
    
    if not document:
        raise HTTPException(
            status_code=404,
            detail=f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_id}"
        )
    
    # 2. íŒŒì‹±ëœ í…ìŠ¤íŠ¸ í™•ì¸ ë° ìë™ íŒŒì‹±
    extracted_text = document.get("extracted_text")
    
    if not extracted_text:
        logger.info(f"âš™ï¸ í…ìŠ¤íŠ¸ ë¯¸ë°œê²¬. ì¦‰ì‹œ íŒŒì‹± ì‹œì‘: {document.get('filename')}")
        try:
            # â­ [ìˆ˜ì •ë¨] ì¸ìë¥¼ 2ê°œì—ì„œ 1ê°œ(file_path)ë§Œ ë³´ë‚´ë„ë¡ ìˆ˜ì •
            parsing_result = await parse_document(document["file_path"])
            
            extracted_text = parsing_result.get("text", "")
            
            if not extracted_text:
                raise ValueError("ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # DBì— ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì €ì¥
            mock_db.update_document(
                document_id, 
                {
                    "extracted_text": extracted_text,
                    "page_count": parsing_result.get("pages", 1)
                }
            )
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(
                status_code=500, 
                detail=f"ë¬¸ì„œ íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
            )
    
    # 3. LLM ì„œë¹„ìŠ¤ í™•ì¸
    if not llm_available():
        raise HTTPException(
            status_code=503,
            detail="AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        )
    
    filename = document.get("filename", "")
    
    try:
        logger.info(f"ğŸ¤– AI ë¶„ì„ ì‹œì‘: {filename}")
        
        # 4. ë¬¸ì„œ ìœ í˜• ê°ì§€
        doc_type = detect_document_type(extracted_text, filename)
        logger.info(f"ğŸ“‹ ê°ì§€ëœ ë¬¸ì„œ ìœ í˜•: {doc_type.value}")
        
        # 5. ìœ í˜•ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸ë¡œ ë¶„ì„
        prompt = get_analysis_prompt(extracted_text, doc_type, filename)
        llm_result = generate_json(prompt)
        
        if not llm_result:
            raise ValueError("LLM ë¶„ì„ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # 6. ë¶„ì„ ê²°ê³¼ êµ¬ì¡°í™”
        analysis_result = {
            "document_id": document_id,
            "summary": llm_result.get("summary", "ìš”ì•½ ìƒì„± ì‹¤íŒ¨"),
            "document_type": llm_result.get("document_type", doc_type.value),
            "importance": llm_result.get("importance", "medium"),
            "key_points": llm_result.get("key_points", []),
            "actions": [
                ActionItem(
                    action=action.get("action", ""),
                    deadline=action.get("deadline"),
                    amount=action.get("amount"),
                    method=action.get("method")
                )
                for action in llm_result.get("actions", [])
            ]
        }
        
        # 7. ì¶”ê°€ ì„¸ë¶€ ì •ë³´ (ë¬¸ì„œ ìœ í˜•ë³„)
        extra_details = {}
        for key in ["tax_details", "prescription_details", "contract_details", 
                    "notice_details", "insurance_details"]:
            if key in llm_result:
                extra_details[key] = llm_result[key]
        
        if extra_details:
            analysis_result["details"] = extra_details
        
        # 8. DBì— ë¶„ì„ ê²°ê³¼ ì €ì¥
        mock_db.update_document(
            document_id,
            {
                "status": "analyzed",
                "analysis_result": analysis_result,
                "document_type": doc_type.value
            }
        )
        
        # 9. ë°±ê·¸ë¼ìš´ë“œì—ì„œ RAG ì¸ë±ì‹±
        background_tasks.add_task(
            _index_document_for_rag,
            document_id,
            extracted_text,
            doc_type.value
        )
        
        logger.info(f"âœ… AI ë¶„ì„ ì™„ë£Œ: {document_id}")
        
        return AnalyzeResponse(**analysis_result)
        
    except ValueError as e:
        logger.error(f"âŒ ì„¤ì • ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"AI ë¶„ì„ ì„¤ì • ì˜¤ë¥˜: {str(e)}"
        )
    
    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        
        # ë¶„ì„ ì‹¤íŒ¨ ìƒíƒœ ì €ì¥
        mock_db.update_document(
            document_id,
            {"status": "analysis_failed", "error": str(e)}
        )
        
        raise HTTPException(
            status_code=500,
            detail=f"ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


async def _index_document_for_rag(document_id: str, text: str, doc_type: str):
    """
    ë°±ê·¸ë¼ìš´ë“œ RAG ì¸ë±ì‹±
    """
    try:
        logger.info(f"ğŸ“š RAG ì¸ë±ì‹± ì‹œì‘: {document_id}")
        
        rag = get_rag_system()
        
        if rag.has_document(document_id):
            logger.info(f"â­ï¸ ì´ë¯¸ ì¸ë±ì‹±ë¨: {document_id}")
            return
        
        chunks = _chunker.chunk(text, document_id)
        
        chunk_count = rag.add_document(
            document_id,
            text,
            metadata={"document_type": doc_type}
        )
        
        mock_db.update_document(
            document_id,
            {
                "rag_indexed": True,
                "chunk_count": chunk_count
            }
        )
        
        logger.info(f"âœ… RAG ì¸ë±ì‹± ì™„ë£Œ: {chunk_count}ê°œ ì²­í¬")
        
    except Exception as e:
        logger.error(f"âŒ RAG ì¸ë±ì‹± ì‹¤íŒ¨: {e}")


@router.get("/status/{document_id}")
async def get_analysis_status(document_id: str):
    """
    ë¶„ì„ ìƒíƒœ ì¡°íšŒ
    """
    document = mock_db.get_document(document_id)
    
    if not document:
        raise HTTPException(
            status_code=404,
            detail=f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_id}"
        )
    
    rag = get_rag_system()
    rag_indexed = rag.has_document(document_id)
    
    return {
        "document_id": document_id,
        "filename": document.get("filename"),
        "status": document["status"],
        "document_type": document.get("document_type"),
        "has_analysis": document.get("analysis_result") is not None,
        "has_text": document.get("extracted_text") is not None,
        "rag_indexed": rag_indexed,
        "chunk_count": document.get("chunk_count", 0)
    }


@router.post("/reanalyze/{document_id}")
async def reanalyze_document(
    document_id: str,
    background_tasks: BackgroundTasks,
    force_type: Optional[str] = None
):
    """
    ë¬¸ì„œ ì¬ë¶„ì„
    """
    document = mock_db.get_document(document_id)
    
    if not document:
        raise HTTPException(
            status_code=404,
            detail=f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_id}"
        )
    
    extracted_text = document.get("extracted_text")
    
    if not extracted_text:
        raise HTTPException(
            status_code=400,
            detail="ë¬¸ì„œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
        )
    
    mock_db.update_document(document_id, {"status": "reanalyzing"})
    
    rag = get_rag_system()
    rag.remove_document(document_id)
    
    request = AnalyzeRequest(document_id=document_id)
    return await analyze_document(request, background_tasks)


@router.get("/types")
async def get_supported_document_types():
    """
    ì§€ì›ë˜ëŠ” ë¬¸ì„œ ìœ í˜• ëª©ë¡
    """
    return {
        "supported_types": [
            {"code": dt.name, "name": dt.value}
            for dt in DocumentType
        ],
        "total": len(DocumentType)
    }