"""
Document Parser Service
PDF, HWP, DOCX, ì´ë¯¸ì§€ íŒŒì¼ íŒŒì‹±ì„ ì²˜ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤
EasyOCR ê¸°ë°˜ìœ¼ë¡œ ìµœì í™”ë¨
"""

import os
import logging
from typing import Dict, Any, Optional, List
from abc import ABC, abstractmethod
from pathlib import Path
import mimetypes
import re

# PDF íŒŒì‹±
import fitz  # PyMuPDF
import pdfplumber
from PyPDF2 import PdfReader

# DOCX íŒŒì‹±
from docx import Document as DocxDocument

# HWP íŒŒì‹±
import olefile
import zipfile
import xml.etree.ElementTree as ET

# ì´ë¯¸ì§€/OCR (EasyOCR)
import numpy as np
from PIL import Image
import easyocr

logger = logging.getLogger(__name__)

# ğŸ”¹ ì „ì—­ OCR Reader (í•œ ë²ˆë§Œ ë¡œë“œ)
_OCR_READER = None

def get_ocr_reader():
    """EasyOCR Readerë¥¼ í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ì¬ì‚¬ìš©"""
    global _OCR_READER
    if _OCR_READER is None:
        logger.info("Initializing EasyOCR Reader...")
        _OCR_READER = easyocr.Reader(['ko', 'en'], gpu=False)
    return _OCR_READER


def clean_pdf_text(text: str) -> str:
    """
    PDFì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì œê±°
    - í°íŠ¸ ì¸ì½”ë”© ë°ì´í„° (Base64)
    - ê°ì£¼ ë²ˆí˜¸ë§Œ ìˆëŠ” ì¤„
    - PDF ë©”íƒ€ë°ì´í„°
    """
    if not text:
        return ""
    
    lines = text.split('\n')
    cleaned_lines = []
    
    for line in lines:
        stripped = line.strip()
        
        # ë¹ˆ ì¤„ì€ ìœ ì§€
        if not stripped:
            cleaned_lines.append('')
            continue
        
        # Base64ë¡œ ë³´ì´ëŠ” ê¸´ ë¬¸ìì—´ì´ 80% ì´ìƒì¸ ì¤„ ì œê±°
        if len(stripped) > 20:
            base64_chars = len(re.findall(r'[A-Za-z0-9+/=]', stripped))
            if base64_chars / len(stripped) > 0.8:
                continue
        
        # ê°ì£¼ ë²ˆí˜¸ë§Œ ìˆëŠ” ì¤„ (^1, ^2, (^3) ë“±)
        if re.match(r'^\(?\^?\d+[\.\)]\)?\s*$', stripped):
            continue
        
        # PDF ë©”íƒ€ë°ì´í„° í‚¤ì›Œë“œë§Œ ìˆëŠ” ì¤„
        if stripped in ['SHA1', 'MD5', '{}', '[]', '()', 'IAA=']:
            continue
        
        # "--- Page N ---" êµ¬ë¶„ì„ ì€ ìœ ì§€
        if stripped.startswith('--- Page'):
            cleaned_lines.append(line)
            continue
        
        # ë‚˜ë¨¸ì§€ëŠ” ìœ ì§€
        cleaned_lines.append(line)
    
    text = '\n'.join(cleaned_lines)
    
    # ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬ (3ì¤„ ì´ìƒ â†’ 2ì¤„)
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()


class DocumentParser(ABC):
    """ë¬¸ì„œ íŒŒì„œ ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def parse(self, file_path: str) -> Dict[str, Any]:
        """
        íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œ
        
        Args:
            file_path: íŒŒì‹±í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            {
                "text": str,           # ì¶”ì¶œëœ í…ìŠ¤íŠ¸
                "page_count": int,     # í˜ì´ì§€ ìˆ˜
                "has_tables": bool,    # í…Œì´ë¸” í¬í•¨ ì—¬ë¶€
                "confidence": float,   # ì‹ ë¢°ë„ (OCRì˜ ê²½ìš°)
                "metadata": dict       # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            }
        """
        pass
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r'\s+', ' ', text)
        
        # ì—°ì†ëœ ì¤„ë°”ê¿ˆ ì •ë¦¬ (3ê°œ ì´ìƒ â†’ 2ê°œ)
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # ì–‘ìª½ ê³µë°± ì œê±°
        text = text.strip()
        
        return text


class PDFParser(DocumentParser):
    """PDF íŒŒì¼ íŒŒì„œ - PyMuPDF + pdfplumber ì¡°í•©"""
    
    async def parse(self, file_path: str) -> Dict[str, Any]:
        """PDF íŒŒì‹± - ë²¡í„° í…ìŠ¤íŠ¸ ìš°ì„  â†’ OCR í´ë°±"""
        try:
            logger.info(f"Parsing PDF file: {file_path}")
            
            # ---------------- 1. ë²¡í„° í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF) ----------------
            doc = fitz.open(file_path)
            text_parts = []
            has_tables = False
            page_count = len(doc)
            
            for page_num, page in enumerate(doc):
                # í…ìŠ¤íŠ¸ ì¶”ì¶œ
                page_text = page.get_text("text")
                
                if page_text.strip():
                    text_parts.append(page_text)
            
            # í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„íˆ ì¶”ì¶œë˜ì—ˆìœ¼ë©´ ì¢…ë£Œ
            full_text = "\n\n".join(text_parts)
            
            if len(full_text.strip()) > 100:  # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´
                doc.close()
                
                # pdfplumberë¡œ í…Œì´ë¸” ê°ì§€
                try:
                    with pdfplumber.open(file_path) as pdf:
                        for page in pdf.pages:
                            if page.extract_tables():
                                has_tables = True
                                break
                except:
                    pass
                
                # í…ìŠ¤íŠ¸ ì •ì œ
                full_text = clean_pdf_text(full_text)
                
                # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
                metadata = self._extract_pdf_metadata(file_path)
                
                result = {
                    "text": full_text,
                    "page_count": page_count,
                    "has_tables": has_tables,
                    "confidence": 1.0,
                    "metadata": metadata
                }
                
                logger.info(f"PDF parsing completed: {page_count} pages, {len(full_text)} chars")
                return result
            
            # ---------------- 2. ì´ë¯¸ì§€ ê¸°ë°˜ OCR (ë²¡í„° í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš°) ----------------
            logger.info("Vector text not found, trying OCR...")
            reader = get_ocr_reader()
            ocr_text_parts = []
            
            for page_num in range(page_count):
                page = doc[page_num]
                # ê³ í•´ìƒë„ë¡œ ë Œë”ë§ (3ë°° í™•ëŒ€)
                pix = page.get_pixmap(matrix=fitz.Matrix(3, 3))
                
                # Pixmapì„ NumPy ë°°ì—´ë¡œ ë³€í™˜
                img_np = np.frombuffer(pix.samples, dtype=np.uint8).reshape(
                    pix.height, pix.width, pix.n
                )
                
                # EasyOCR ì‹¤í–‰
                results = reader.readtext(img_np, detail=0, paragraph=False)
                page_text = "\n".join(results)
                
                if page_text.strip():
                    ocr_text_parts.append(f"--- Page {page_num + 1} ---\n{page_text}")
            
            doc.close()
            
            if ocr_text_parts:
                full_text = "\n\n".join(ocr_text_parts)
                full_text = clean_pdf_text(full_text)
                
                result = {
                    "text": full_text,
                    "page_count": page_count,
                    "has_tables": False,
                    "confidence": 0.85,  # OCR ì‹ ë¢°ë„
                    "metadata": self._extract_pdf_metadata(file_path)
                }
                
                logger.info(f"PDF OCR completed: {page_count} pages, {len(full_text)} chars")
                return result
            else:
                return {
                    "text": "[PDF OCR ê²°ê³¼ ì—†ìŒ]",
                    "page_count": page_count,
                    "has_tables": False,
                    "confidence": 0.0,
                    "metadata": {}
                }
                
        except Exception as e:
            logger.error(f"PDF parsing failed: {str(e)}")
            raise Exception(f"PDF íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    
    def _extract_pdf_metadata(self, file_path: str) -> Dict[str, Any]:
        """PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            reader = PdfReader(file_path)
            info = reader.metadata
            
            return {
                "title": info.get('/Title', ''),
                "author": info.get('/Author', ''),
                "subject": info.get('/Subject', ''),
                "creator": info.get('/Creator', ''),
                "producer": info.get('/Producer', ''),
                "creation_date": info.get('/CreationDate', ''),
            }
        except:
            return {}


class DOCXParser(DocumentParser):
    """DOCX íŒŒì¼ íŒŒì„œ - í—¤ë”/í‘¸í„° í¬í•¨"""
    
    async def parse(self, file_path: str) -> Dict[str, Any]:
        """DOCX íŒŒì‹± - ë‹¨ë½ + í‘œ + í—¤ë”/í‘¸í„°"""
        try:
            logger.info(f"Parsing DOCX file: {file_path}")
            
            doc = DocxDocument(file_path)
            text_parts = []
            has_tables = False
            
            # ë³¸ë¬¸ ë‹¨ë½ ì¶”ì¶œ
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text_parts.append(paragraph.text.strip())
            
            # í…Œì´ë¸” ì¶”ì¶œ
            if doc.tables:
                has_tables = True
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            if cell.text.strip():
                                text_parts.append(cell.text.strip())
            
            # ì„¹ì…˜ë³„ í—¤ë”/í‘¸í„° ì¶”ì¶œ
            for section in doc.sections:
                # í—¤ë”
                header = section.header
                for p in header.paragraphs:
                    if p.text.strip():
                        text_parts.append(p.text.strip())
                
                # í‘¸í„°
                footer = section.footer
                for p in footer.paragraphs:
                    if p.text.strip():
                        text_parts.append(p.text.strip())
            
            # ì „ì²´ í…ìŠ¤íŠ¸
            full_text = "\n\n".join(text_parts)
            full_text = self.clean_text(full_text)
            
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                "author": doc.core_properties.author or "",
                "title": doc.core_properties.title or "",
                "subject": doc.core_properties.subject or "",
                "created": str(doc.core_properties.created) if doc.core_properties.created else "",
                "modified": str(doc.core_properties.modified) if doc.core_properties.modified else "",
            }
            
            result = {
                "text": full_text if text_parts else "[DOCX ì¶”ì¶œ ê²°ê³¼ ì—†ìŒ]",
                "page_count": len(doc.paragraphs),
                "has_tables": has_tables,
                "confidence": 1.0,
                "metadata": metadata
            }
            
            logger.info(f"DOCX parsing completed: {len(full_text)} chars")
            return result
            
        except Exception as e:
            logger.error(f"DOCX parsing failed: {str(e)}")
            raise Exception(f"DOCX íŒŒì‹± ì‹¤íŒ¨: {str(e)}")


class HWPParser(DocumentParser):
    """HWP íŒŒì¼ íŒŒì„œ - HWPX ì‹ ë²„ì „ + OLE êµ¬ë²„ì „ ì§€ì›"""
    
    async def parse(self, file_path: str) -> Dict[str, Any]:
        """HWP íŒŒì‹± - ì‹ ë²„ì „(HWPX) ìš°ì„  â†’ êµ¬ë²„ì „(OLE) í´ë°±"""
        try:
            logger.info(f"Parsing HWP file: {file_path}")
            
            file_extension = os.path.splitext(file_path)[1].lower()
            
            # ---------------- 1. ì‹ ë²„ì „ HWPX (ZIP/XML ê¸°ë°˜) ----------------
            if file_extension == '.hwpx' or zipfile.is_zipfile(file_path):
                try:
                    text_content = []
                    
                    with zipfile.ZipFile(file_path, 'r') as z:
                        # HWPX êµ¬ì¡°: Contents/*.xmlì— í…ìŠ¤íŠ¸ ì¡´ì¬
                        for name in z.namelist():
                            if name.startswith('Contents/') and name.endswith('.xml'):
                                xml_data = z.read(name)
                                root = ET.fromstring(xml_data)
                                
                                # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì œê±° (ê²€ìƒ‰ ë‹¨ìˆœí™”)
                                for elem in root.iter():
                                    if '}' in elem.tag:
                                        elem.tag = elem.tag.split('}', 1)[1]
                                
                                # 't' íƒœê·¸ì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                for elem in root.iter('t'):
                                    if elem.text:
                                        text_content.append(elem.text)
                    
                    if text_content:
                        full_text = " ".join(text_content).strip()
                        full_text = self.clean_text(full_text)
                        
                        result = {
                            "text": full_text,
                            "page_count": 1,
                            "has_tables": False,
                            "confidence": 0.95,
                            "metadata": {}
                        }
                        
                        logger.info(f"HWPX parsing completed: {len(full_text)} chars")
                        return result
                        
                except Exception as e:
                    logger.warning(f"HWPX parsing failed, trying OLE format: {e}")
            
            # ---------------- 2. êµ¬ë²„ì „ OLE HWP ----------------
            if olefile.isOleFile(file_path):
                text_content = []
                
                with olefile.OleFileIO(file_path) as f:
                    # BodyText/SectionN ìŠ¤íŠ¸ë¦¼ íƒìƒ‰
                    for i in range(256):
                        stream_name = f"BodyText/Section{i}"
                        if f.exists(stream_name):
                            try:
                                stream_data = f.openstream(stream_name).read()
                                
                                # UTF-16 ë””ì½”ë”©
                                text = stream_data.decode('UTF-16', errors='ignore')
                                
                                # ì œì–´ ë¬¸ì ì œê±°
                                text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
                                
                                # Base64 ê°™ì€ ê¸´ ë¬¸ìì—´ ì œê±°
                                text = re.sub(r'[A-Za-z0-9+/=]{30,}', '', text)
                                
                                if text.strip():
                                    text_content.append(text.strip())
                                    
                            except Exception as e:
                                logger.warning(f"Failed to parse section {i}: {e}")
                                continue
                
                if text_content:
                    full_text = "\n\n".join(text_content)
                    full_text = self.clean_text(full_text)
                    
                    result = {
                        "text": full_text,
                        "page_count": len(text_content),
                        "has_tables": False,
                        "confidence": 0.9,
                        "metadata": {}
                    }
                    
                    logger.info(f"HWP OLE parsing completed: {len(full_text)} chars")
                    return result
                else:
                    return {
                        "text": "[HWP ì¶”ì¶œ ì˜¤ë¥˜]: ë³¸ë¬¸ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "page_count": 0,
                        "has_tables": False,
                        "confidence": 0.0,
                        "metadata": {}
                    }
            
            # ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹
            return {
                "text": "[HWP ì¶”ì¶œ ì˜¤ë¥˜]: ì§€ì›í•˜ì§€ ì•ŠëŠ” HWP íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.",
                "page_count": 0,
                "has_tables": False,
                "confidence": 0.0,
                "metadata": {}
            }
            
        except Exception as e:
            logger.error(f"HWP parsing failed: {str(e)}")
            raise Exception(f"HWP íŒŒì‹± ì‹¤íŒ¨: {str(e)}")


class ImageParser(DocumentParser):
    """ì´ë¯¸ì§€ íŒŒì¼ íŒŒì„œ (EasyOCR) - Yì¢Œí‘œ ì •ë ¬ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° ìˆœì„œ"""
    
    async def parse(self, file_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ OCR - EasyOCR ì‚¬ìš©"""
        try:
            logger.info(f"Parsing image file: {file_path}")
            
            # ì´ë¯¸ì§€ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
            try:
                img = Image.open(file_path)
                img.verify()  # ì´ë¯¸ì§€ ì†ìƒ í™•ì¸
                img = Image.open(file_path)  # verify() í›„ ë‹¤ì‹œ ì—´ê¸°
            except Exception as img_error:
                logger.error(f"Image file read error: {img_error}")
                raise Exception(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_error}")
            
            # RGBë¡œ ë³€í™˜
            if img.mode not in ('RGB', 'L'):
                img = img.convert('RGB')
            
            # NumPy ë°°ì—´ë¡œ ë³€í™˜
            img_array = np.array(img)
            
            if img_array is None or img_array.size == 0:
                raise Exception("ì´ë¯¸ì§€ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤")
            
            logger.debug(f"Image loaded: {img_array.shape}")
            
            # EasyOCR ì‹¤í–‰ (detail=1: bbox í¬í•¨)
            reader = get_ocr_reader()
            results = reader.readtext(img_array, detail=1, paragraph=False)
            
            if not results:
                return {
                    "text": "[ì´ë¯¸ì§€ OCR ê²°ê³¼ ì—†ìŒ]",
                    "page_count": 1,
                    "has_tables": False,
                    "confidence": 0.0,
                    "metadata": {
                        "width": img.size[0],
                        "height": img.size[1],
                        "format": img.format,
                        "mode": img.mode,
                    }
                }
            
            # Y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
            sorted_results = sorted(results, key=lambda x: x[0][0][1])
            
            # ì¤„ë°”ê¿ˆ ê°ì§€ (Y ì¢Œí‘œ ì°¨ì´ë¡œ íŒë‹¨)
            lines = []
            current_line = []
            prev_y = None
            line_height_threshold = 30  # í”½ì…€ ë‹¨ìœ„
            confidences = []
            
            for bbox, text, confidence in sorted_results:
                current_y = bbox[0][1]  # ì¢Œìƒë‹¨ Y ì¢Œí‘œ
                
                # ìƒˆë¡œìš´ ì¤„ì¸ì§€ íŒë‹¨
                if prev_y is None or abs(current_y - prev_y) > line_height_threshold:
                    if current_line:
                        lines.append(" ".join(current_line))
                    current_line = [text]
                else:
                    current_line.append(text)
                
                prev_y = current_y
                confidences.append(confidence)
            
            # ë§ˆì§€ë§‰ ì¤„ ì¶”ê°€
            if current_line:
                lines.append(" ".join(current_line))
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            full_text = "\n".join(lines)
            full_text = re.sub(r' +', ' ', full_text)  # ì—°ì† ê³µë°± ì œê±°
            full_text = re.sub(r'\n\s+\n', '\n\n', full_text)  # ë¹ˆ ì¤„ ì •ë¦¬
            full_text = full_text.strip()
            
            # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0
            
            # ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°
            metadata = {
                "width": img.size[0],
                "height": img.size[1],
                "format": img.format,
                "mode": img.mode,
            }
            
            result = {
                "text": full_text,
                "page_count": 1,
                "has_tables": False,
                "confidence": avg_confidence,
                "metadata": metadata
            }
            
            logger.info(f"Image OCR completed: {len(full_text)} chars, confidence: {avg_confidence:.2%}")
            return result
            
        except Exception as e:
            logger.error(f"Image parsing failed: {str(e)}")
            raise Exception(f"ì´ë¯¸ì§€ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")


class DocumentParserFactory:
    """íŒŒì„œ íŒ©í† ë¦¬ - íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ íŒŒì„œ ì„ íƒ"""
    
    # íŒŒì¼ í™•ì¥ìë³„ íŒŒì„œ ë§¤í•‘
    PARSER_MAP = {
        '.pdf': PDFParser,
        '.docx': DOCXParser,
        '.doc': DOCXParser,
        '.hwp': HWPParser,
        '.jpg': ImageParser,
        '.jpeg': ImageParser,
        '.png': ImageParser,
        '.gif': ImageParser,
        '.bmp': ImageParser,
        '.tiff': ImageParser,
    }
    
    @classmethod
    def get_parser(cls, file_type: str) -> DocumentParser:
        """
        íŒŒì¼ íƒ€ì…ì— ë§ëŠ” íŒŒì„œ ë°˜í™˜
        
        Args:
            file_type: íŒŒì¼ í™•ì¥ì (ì˜ˆ: '.pdf', '.hwp')
            
        Returns:
            DocumentParser ì¸ìŠ¤í„´ìŠ¤
            
        Raises:
            ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íƒ€ì…
        """
        file_type = file_type.lower()
        
        parser_class = cls.PARSER_MAP.get(file_type)
        if not parser_class:
            supported = ', '.join(cls.PARSER_MAP.keys())
            raise ValueError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_type}\n"
                f"ì§€ì› í˜•ì‹: {supported}"
            )
        
        return parser_class()
    
    @classmethod
    def detect_file_type(cls, file_path: str) -> str:
        """
        íŒŒì¼ ê²½ë¡œì—ì„œ íŒŒì¼ íƒ€ì… ê°ì§€
        
        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            
        Returns:
            íŒŒì¼ í™•ì¥ì (ì˜ˆ: '.pdf')
        """
        # í™•ì¥ì ì¶”ì¶œ
        ext = Path(file_path).suffix.lower()
        
        # MIME íƒ€ì…ìœ¼ë¡œ ê²€ì¦
        mime_type, _ = mimetypes.guess_type(file_path)
        
        # MIME íƒ€ì…ê³¼ í™•ì¥ìê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        if mime_type:
            logger.debug(f"Detected MIME type: {mime_type}")
        
        return ext
    
    @classmethod
    async def parse_file(cls, file_path: str) -> Dict[str, Any]:
        """
        íŒŒì¼ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ íŒŒì‹±
        
        Args:
            file_path: íŒŒì‹±í•  íŒŒì¼ ê²½ë¡œ
            
        Returns:
            íŒŒì‹± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        # íŒŒì¼ íƒ€ì… ê°ì§€
        file_type = cls.detect_file_type(file_path)
        
        # íŒŒì„œ ì„ íƒ ë° íŒŒì‹±
        parser = cls.get_parser(file_type)
        result = await parser.parse(file_path)
        
        # íŒŒì¼ íƒ€ì… ì •ë³´ ì¶”ê°€
        result['file_type'] = file_type
        result['file_name'] = Path(file_path).name
        result['file_size'] = os.path.getsize(file_path)
        
        return result


# í¸ì˜ í•¨ìˆ˜
async def parse_document(file_path: str) -> Dict[str, Any]:
    """
    ë¬¸ì„œ íŒŒì‹± í¸ì˜ í•¨ìˆ˜
    
    Usage:
        result = await parse_document("document.pdf")
        print(result['text'])
    """
    return await DocumentParserFactory.parse_file(file_path)