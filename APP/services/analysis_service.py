"""
ë¬¸ì„œ ë¶„ì„ ì„œë¹„ìŠ¤ (ë¦¬íŒ©í† ë§)

ì—­í• :
- ë¬¸ì„œ ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- LLM ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•œ ìš”ì•½/ë¶„ì„
- ì •ê·œì‹ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ (ë³´ì¡°)

ì˜ì¡´ì„±:
- llm_service.py: LLM API í˜¸ì¶œ
- rag_service.py: RAG ì‹œìŠ¤í…œ (ì±„íŒ…ìš©)
"""
import re
import logging
from typing import Dict, List, Optional
from datetime import datetime

from APP.services.llm_service import (
    analyze_document as llm_analyze,
    is_available as llm_available
)
from APP.services.rag_service import add_document, get_rag_system

logger = logging.getLogger(__name__)


# ============================================
# ë©”ì¸ ë¶„ì„ í•¨ìˆ˜
# ============================================

def analyze_document_with_llm(text: str, filename: str) -> Dict:
    """
    LLMì„ ì‚¬ìš©í•œ ë¬¸ì„œ ë¶„ì„
    
    Args:
        text: íŒŒì‹±ëœ ë¬¸ì„œ í…ìŠ¤íŠ¸
        filename: íŒŒì¼ëª…
        
    Returns:
        êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼:
        {
            "summary": str,
            "document_type": str,
            "importance": str,
            "key_points": List[str],
            "actions": List[Dict]
        }
    """
    if not llm_available():
        logger.warning("âš ï¸ LLM ì„œë¹„ìŠ¤ ë¶ˆê°€ - ê¸°ë³¸ ë¶„ì„ ì‚¬ìš©")
        return _fallback_analysis(text, filename)
    
    try:
        # LLM ë¶„ì„ ì‹¤í–‰
        result = llm_analyze(text, filename)
        
        # ì •ê·œì‹ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ ë³´ê°•
        extracted = extract_key_info(text)
        result["extracted_entities"] = extracted
        
        logger.info(f"âœ… ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ: {filename}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
        return _fallback_analysis(text, filename)


def analyze_and_index(document_id: str, text: str, filename: str) -> Dict:
    """
    ë¬¸ì„œ ë¶„ì„ + RAG ì¸ë±ì‹±
    
    ë¶„ì„ê³¼ ë™ì‹œì— RAG ì‹œìŠ¤í…œì— ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ì—¬
    ì´í›„ ì±„íŒ…ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    
    Args:
        document_id: ë¬¸ì„œ ID
        text: ë¬¸ì„œ í…ìŠ¤íŠ¸
        filename: íŒŒì¼ëª…
        
    Returns:
        ë¶„ì„ ê²°ê³¼ (+ chunk_count í¬í•¨)
    """
    # 1. ë¬¸ì„œ ë¶„ì„
    result = analyze_document_with_llm(text, filename)
    
    # 2. RAG ì¸ë±ì‹± (ë¹„ë™ê¸° ê°€ëŠ¥)
    try:
        chunk_count = add_document(document_id, text)
        result["rag_indexed"] = True
        result["chunk_count"] = chunk_count
        logger.info(f"âœ… RAG ì¸ë±ì‹± ì™„ë£Œ: {chunk_count}ê°œ ì²­í¬")
    except Exception as e:
        logger.warning(f"âš ï¸ RAG ì¸ë±ì‹± ì‹¤íŒ¨: {e}")
        result["rag_indexed"] = False
        result["chunk_count"] = 0
    
    return result


# ============================================
# ì •ê·œì‹ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ
# ============================================

def extract_key_info(text: str) -> Dict:
    """
    ì •ê·œì‹ìœ¼ë¡œ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
    
    Args:
        text: ë¬¸ì„œ í…ìŠ¤íŠ¸
        
    Returns:
        {
            "dates": [...],
            "amounts": [...],
            "phone_numbers": [...],
            "accounts": [...]
        }
    """
    info = {
        "dates": [],
        "amounts": [],
        "phone_numbers": [],
        "accounts": []
    }
    
    # ë‚ ì§œ ì¶”ì¶œ
    date_patterns = [
        r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼',  # 2025ë…„ 3ì›” 15ì¼
        r'(\d{4})[./-](\d{1,2})[./-](\d{1,2})',     # 2025.03.15, 2025-03-15
    ]
    
    for pattern in date_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            try:
                year, month, day = int(match[0]), int(match[1]), int(match[2])
                date_str = f"{year:04d}-{month:02d}-{day:02d}"
                if date_str not in info["dates"]:
                    info["dates"].append(date_str)
            except (ValueError, IndexError):
                continue
    
    # ê¸ˆì•¡ ì¶”ì¶œ
    amount_patterns = [
        r'(\d{1,3}(?:,\d{3})+)\s*ì›',  # 1,000,000ì›
        r'(\d+)\s*ì›',                   # 10000ì›
    ]
    
    for pattern in amount_patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            amount_str = match.replace(',', '')
            if amount_str.isdigit():
                amount = int(amount_str)
                if amount not in info["amounts"] and amount >= 100:  # 100ì› ì´ìƒë§Œ
                    info["amounts"].append(amount)
    
    # ì „í™”ë²ˆí˜¸ ì¶”ì¶œ
    phone_pattern = r'(\d{2,3})-(\d{3,4})-(\d{4})'
    matches = re.findall(phone_pattern, text)
    for match in matches:
        phone = f"{match[0]}-{match[1]}-{match[2]}"
        if phone not in info["phone_numbers"]:
            info["phone_numbers"].append(phone)
    
    # ê³„ì¢Œë²ˆí˜¸ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´)
    account_pattern = r'(\d{3,4})-(\d{2,4})-(\d{4,6})'
    matches = re.findall(account_pattern, text)
    for match in matches:
        account = f"{match[0]}-{match[1]}-{match[2]}"
        # ì „í™”ë²ˆí˜¸ì™€ êµ¬ë¶„ (ìë¦¿ìˆ˜ë¡œ)
        if len(account.replace('-', '')) >= 10 and account not in info["accounts"]:
            info["accounts"].append(account)
    
    return info


def extract_action_items(text: str) -> List[Dict]:
    """
    í–‰ë™ í•­ëª© ì¶”ì¶œ (ì •ê·œì‹ ê¸°ë°˜)
    
    LLM ë¶„ì„ ì‹¤íŒ¨ ì‹œ í´ë°±ìœ¼ë¡œ ì‚¬ìš©
    """
    actions = []
    info = extract_key_info(text)
    
    # ë‚©ë¶€/ì œì¶œ ê´€ë ¨ í‚¤ì›Œë“œ íƒì§€
    action_keywords = {
        "ë‚©ë¶€": ["ë‚©ë¶€", "ì§€ë¶ˆ", "ì†¡ê¸ˆ", "ì…ê¸ˆ"],
        "ì œì¶œ": ["ì œì¶œ", "ì‹ ì²­", "ì ‘ìˆ˜", "ë“±ë¡"],
        "ë°©ë¬¸": ["ë°©ë¬¸", "ì¶œì„", "ì°¸ì„"],
        "ì—°ë½": ["ì—°ë½", "ë¬¸ì˜", "ì „í™”"],
    }
    
    for action_type, keywords in action_keywords.items():
        for keyword in keywords:
            if keyword in text:
                action = {
                    "action": f"{action_type} í•„ìš”",
                    "deadline": info["dates"][0] if info["dates"] else None,
                    "amount": info["amounts"][0] if info["amounts"] and action_type == "ë‚©ë¶€" else None,
                    "method": None
                }
                actions.append(action)
                break  # í•œ ìœ í˜•ë‹¹ í•˜ë‚˜ë§Œ
    
    return actions


# ============================================
# í´ë°± ë¶„ì„ (LLM ì‹¤íŒ¨ ì‹œ)
# ============================================

def _fallback_analysis(text: str, filename: str) -> Dict:
    """LLM ì—†ì´ ê¸°ë³¸ ë¶„ì„"""
    info = extract_key_info(text)
    actions = extract_action_items(text)
    
    # ë¬¸ì„œ ìœ í˜• ì¶”ì¸¡
    doc_type = _guess_document_type(filename, text)
    
    # ìš”ì•½ ìƒì„± (ì²« 500ì)
    summary = text[:500].strip()
    if len(text) > 500:
        summary += "..."
    
    # ì¤‘ìš”ë„ íŒë‹¨
    importance = "medium"
    if info["amounts"] and max(info["amounts"]) > 100000:
        importance = "high"
    if any(keyword in text for keyword in ["ê¸´ê¸‰", "ì¦‰ì‹œ", "ë§ˆê°"]):
        importance = "high"
    
    return {
        "summary": summary,
        "document_type": doc_type,
        "importance": importance,
        "key_points": [
            f"ë‚ ì§œ: {', '.join(info['dates'][:3])}" if info['dates'] else "ë‚ ì§œ ì •ë³´ ì—†ìŒ",
            f"ê¸ˆì•¡: {', '.join(str(a) + 'ì›' for a in info['amounts'][:3])}" if info['amounts'] else "ê¸ˆì•¡ ì •ë³´ ì—†ìŒ",
            f"ì—°ë½ì²˜: {', '.join(info['phone_numbers'][:2])}" if info['phone_numbers'] else "ì—°ë½ì²˜ ì •ë³´ ì—†ìŒ",
        ],
        "actions": actions,
        "extracted_entities": info
    }


def _guess_document_type(filename: str, text: str = "") -> str:
    """íŒŒì¼ëª…ê³¼ ë‚´ìš©ìœ¼ë¡œ ë¬¸ì„œ ìœ í˜• ì¶”ì¸¡"""
    combined = (filename + " " + text[:1000]).lower()
    
    type_keywords = {
        "ì„¸ê¸ˆê³ ì§€ì„œ": ["ì„¸ê¸ˆ", "ë‚©ì„¸", "ê³¼ì„¸", "ì§€ë°©ì„¸", "êµ­ì„¸", "ê³ ì§€"],
        "ì „ìì²˜ë°©ì „": ["ì²˜ë°©", "ì˜ì•½í’ˆ", "ì¡°ì œ", "ì•½êµ­", "ë³µìš©"],
        "í†µì§€ì„œ": ["í†µì§€", "ì•ˆë‚´", "ì•Œë¦¼", "ê³µê³ "],
        "ê³„ì•½ì„œ": ["ê³„ì•½", "ì•½ì •", "í•©ì˜", "ë™ì˜"],
        "ì¦ëª…ì„œ": ["ì¦ëª…", "í™•ì¸ì„œ", "ë°œê¸‰"],
        "ì‹ ì²­ì„œ": ["ì‹ ì²­", "ì ‘ìˆ˜", "ë“±ë¡"],
        "ì²­êµ¬ì„œ": ["ì²­êµ¬", "ìš”ê¸ˆ", "ì´ìš©ë£Œ"],
    }
    
    for doc_type, keywords in type_keywords.items():
        if any(kw in combined for kw in keywords):
            return doc_type
    
    return "ê³µê³µë¬¸ì„œ"


# ============================================
# í…ŒìŠ¤íŠ¸
# ============================================

if __name__ == "__main__":
    print("=" * 60)
    print("Analysis Service í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    test_text = """
    ì§€ë°©ì„¸ ë‚©ë¶€ ê³ ì§€ì„œ
    
    ë‚©ì„¸ì: í™ê¸¸ë™
    ì£¼ì†Œ: ì„œìš¸ì‹œ ê°•ë‚¨êµ¬
    
    ë‚©ë¶€ ê¸°í•œ: 2025ë…„ 3ì›” 31ì¼
    ë‚©ë¶€ ê¸ˆì•¡: 250,000ì›
    
    ë‚©ë¶€ ë°©ë²•:
    - ìœ„íƒìŠ¤ (www.wetax.go.kr)
    - ì€í–‰ ë°©ë¬¸ ë‚©ë¶€
    - ê°€ìƒê³„ì¢Œ: 123-456-789012
    
    ë¬¸ì˜: ì„¸ë¬´ê³¼ 02-1234-5678
    
    ê¸°í•œ ë‚´ ë¯¸ë‚© ì‹œ ê°€ì‚°ì„¸ê°€ ë¶€ê³¼ë©ë‹ˆë‹¤.
    """
    
    # ì •ê·œì‹ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    print("\nğŸ“Œ ì •ê·œì‹ ì¶”ì¶œ ê²°ê³¼:")
    info = extract_key_info(test_text)
    print(f"  ë‚ ì§œ: {info['dates']}")
    print(f"  ê¸ˆì•¡: {info['amounts']}")
    print(f"  ì „í™”: {info['phone_numbers']}")
    
    # LLM ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("\nğŸ“Œ LLM ë¶„ì„ ê²°ê³¼:")
    result = analyze_document_with_llm(test_text, "ì„¸ê¸ˆê³ ì§€ì„œ.pdf")
    print(f"  ìœ í˜•: {result['document_type']}")
    print(f"  ì¤‘ìš”ë„: {result['importance']}")
    print(f"  ìš”ì•½: {result['summary'][:100]}...")