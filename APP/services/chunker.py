"""
ê³ í’ˆì§ˆ ë¬¸ì„œ ì²­í‚¹ ëª¨ë“ˆ

ê¸°ëŠ¥:
- ì˜ë¯¸ ë‹¨ìœ„ ë¶„í•  (ë¬¸ì¥/ë¬¸ë‹¨ ê²½ê³„ ì¸ì‹)
- í…Œì´ë¸” ë°ì´í„° ë³´ì¡´
- ì œëª©/ì†Œì œëª© ê¸°ë°˜ ë¶„í• 
- ì¤‘ì²©(overlap) ìµœì í™”
- ë©”íƒ€ë°ì´í„° ë³´ì¡´
"""
import re
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum

logger = logging.getLogger(__name__)


class ChunkType(Enum):
    """ì²­í¬ ìœ í˜•"""
    PARAGRAPH = "paragraph"
    TABLE = "table"
    TITLE = "title"
    LIST = "list"
    MIXED = "mixed"


@dataclass
class Chunk:
    """ì²­í¬ ë°ì´í„° í´ë˜ìŠ¤"""
    text: str
    index: int
    chunk_type: ChunkType = ChunkType.PARAGRAPH
    start_char: int = 0
    end_char: int = 0
    metadata: Dict = field(default_factory=dict)
    
    @property
    def length(self) -> int:
        return len(self.text)


@dataclass
class ChunkingConfig:
    """ì²­í‚¹ ì„¤ì •"""
    chunk_size: int = 800           # ëª©í‘œ ì²­í¬ í¬ê¸°
    chunk_overlap: int = 150        # ì¤‘ì²© í¬ê¸°
    min_chunk_size: int = 100       # ìµœì†Œ ì²­í¬ í¬ê¸°
    max_chunk_size: int = 1500      # ìµœëŒ€ ì²­í¬ í¬ê¸°
    preserve_tables: bool = True    # í…Œì´ë¸” ë³´ì¡´
    preserve_titles: bool = True    # ì œëª© ë³´ì¡´
    sentence_boundary: bool = True  # ë¬¸ì¥ ê²½ê³„ ë¶„í• 


class SmartChunker:
    """
    ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ì²­ì»¤
    
    ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    
    Usage:
        chunker = SmartChunker()
        chunks = chunker.chunk(text)
    """
    
    def __init__(self, config: ChunkingConfig = None):
        self.config = config or ChunkingConfig()
        
        # ë¬¸ì¥ ì¢…ê²° íŒ¨í„´ (í•œêµ­ì–´ + ì˜ì–´)
        self.sentence_endings = re.compile(
            r'(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+|'  # ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ + ê³µë°±
            r'(?<=ë‹¤\.)\s+|'        # ~ë‹¤. í˜•íƒœ
            r'(?<=ìš”\.)\s+|'        # ~ìš”. í˜•íƒœ
            r'(?<=ìŒ\.)\s+|'        # ~ìŒ. í˜•íƒœ
            r'(?<=ìŠµë‹ˆë‹¤\.)\s+'     # ~ìŠµë‹ˆë‹¤. í˜•íƒœ
        )
        
        # ì œëª© íŒ¨í„´
        self.title_patterns = [
            r'^#{1,6}\s+.+$',                    # ë§ˆí¬ë‹¤ìš´ ì œëª©
            r'^[0-9]+\.\s+.+$',                  # ìˆ«ì. ì œëª©
            r'^[ê°€-í£]\.\s+.+$',                 # ê°€. ë‚˜. ë‹¤. í˜•íƒœ
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\.\s+.+$',  # í•œì ìˆ«ì
            r'^ã€.+ã€‘$',                         # ã€ì œëª©ã€‘
            r'^\[.+\]$',                         # [ì œëª©]
            r'^<.+>$',                           # <ì œëª©>
            r'^ì œ[0-9]+ì¡°',                      # ì œ1ì¡°, ì œ2ì¡°
            r'^[0-9]+\)',                        # 1) 2) í˜•íƒœ
        ]
        
        # í…Œì´ë¸” íŒ¨í„´
        self.table_patterns = [
            r'\|.+\|',                           # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”
            r'â”Œ.*â”',                             # ë°•ìŠ¤ í…Œì´ë¸” ì‹œì‘
            r'â”€{3,}',                            # ê°€ë¡œì„ 
            r'\t.+\t',                           # íƒ­ êµ¬ë¶„ ë°ì´í„°
        ]
        
        # ë¦¬ìŠ¤íŠ¸ íŒ¨í„´
        self.list_patterns = [
            r'^[-â€¢â—â—‹â—†â—‡â–¶â–·]\s+',                  # ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸
            r'^\d+[\.\)]\s+',                    # ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
            r'^[ê°€-í£][\.\)]\s+',                # ê°€) ë‚˜) í˜•íƒœ
        ]
    
    def chunk(self, text: str, document_id: str = "") -> List[Chunk]:
        """
        ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            document_id: ë¬¸ì„œ ID (ë©”íƒ€ë°ì´í„°ìš©)
            
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        if not text or not text.strip():
            return []
        
        # 1. í…ìŠ¤íŠ¸ ì •ê·œí™”
        text = self._normalize_text(text)
        
        # 2. êµ¬ì¡° ë¶„ì„ (ì„¹ì…˜ ë¶„ë¦¬)
        sections = self._split_into_sections(text)
        
        # 3. ì„¹ì…˜ë³„ ì²­í‚¹
        all_chunks = []
        current_index = 0
        
        for section in sections:
            section_chunks = self._chunk_section(
                section["text"],
                section["type"],
                start_index=current_index,
                start_char=section["start"]
            )
            
            for chunk in section_chunks:
                chunk.metadata["document_id"] = document_id
                chunk.metadata["section_type"] = section["type"]
                all_chunks.append(chunk)
            
            current_index += len(section_chunks)
        
        # 4. í›„ì²˜ë¦¬ (ë„ˆë¬´ ì‘ì€ ì²­í¬ ë³‘í•©)
        all_chunks = self._merge_small_chunks(all_chunks)
        
        # 5. ì¸ë±ìŠ¤ ì¬ì •ë ¬
        for i, chunk in enumerate(all_chunks):
            chunk.index = i
        
        logger.info(f"ì²­í‚¹ ì™„ë£Œ: {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")
        return all_chunks
    
    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ì—°ì† ê³µë°± ì •ë¦¬
        text = re.sub(r'[ \t]+', ' ', text)
        
        # ì—°ì† ì¤„ë°”ê¿ˆ ì •ë¦¬ (3ê°œ ì´ìƒ â†’ 2ê°œ)
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # íŠ¹ìˆ˜ ê³µë°± ë¬¸ì ì •ê·œí™”
        text = text.replace('\xa0', ' ')
        text = text.replace('\u200b', '')
        
        return text.strip()
    
    def _split_into_sections(self, text: str) -> List[Dict]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ë‹¨ìœ„ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬
        
        Returns:
            [{"text": "...", "type": "paragraph/table/title", "start": 0}, ...]
        """
        sections = []
        lines = text.split('\n')
        
        current_section = {"text": "", "type": "paragraph", "start": 0}
        current_pos = 0
        
        for line in lines:
            line_type = self._detect_line_type(line)
            
            # í…Œì´ë¸”ì€ ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ
            if line_type == "table":
                if current_section["text"].strip():
                    sections.append(current_section)
                
                # í…Œì´ë¸” ì‹œì‘
                table_text = line + "\n"
                table_start = current_pos
                
                current_section = {
                    "text": table_text,
                    "type": "table",
                    "start": table_start
                }
            
            # ì œëª©ì€ ë‹¤ìŒ ì„¹ì…˜ì˜ ì‹œì‘ì 
            elif line_type == "title" and self.config.preserve_titles:
                if current_section["text"].strip():
                    sections.append(current_section)
                
                current_section = {
                    "text": line + "\n",
                    "type": "title",
                    "start": current_pos
                }
            
            # ì¼ë°˜ í…ìŠ¤íŠ¸
            else:
                if current_section["type"] == "table" and line_type != "table":
                    # í…Œì´ë¸” ì¢…ë£Œ
                    sections.append(current_section)
                    current_section = {
                        "text": line + "\n",
                        "type": "paragraph",
                        "start": current_pos
                    }
                else:
                    current_section["text"] += line + "\n"
            
            current_pos += len(line) + 1
        
        # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
        if current_section["text"].strip():
            sections.append(current_section)
        
        return sections
    
    def _detect_line_type(self, line: str) -> str:
        """ë¼ì¸ ìœ í˜• ê°ì§€"""
        line = line.strip()
        
        if not line:
            return "empty"
        
        # í…Œì´ë¸” ì²´í¬
        for pattern in self.table_patterns:
            if re.search(pattern, line):
                return "table"
        
        # ì œëª© ì²´í¬
        for pattern in self.title_patterns:
            if re.match(pattern, line):
                return "title"
        
        # ë¦¬ìŠ¤íŠ¸ ì²´í¬
        for pattern in self.list_patterns:
            if re.match(pattern, line):
                return "list"
        
        return "paragraph"
    
    def _chunk_section(
        self,
        text: str,
        section_type: str,
        start_index: int,
        start_char: int
    ) -> List[Chunk]:
        """ì„¹ì…˜ì„ ì²­í¬ë¡œ ë¶„í• """
        
        # í…Œì´ë¸”ì€ ë¶„í• í•˜ì§€ ì•ŠìŒ
        if section_type == "table" and self.config.preserve_tables:
            return [Chunk(
                text=text.strip(),
                index=start_index,
                chunk_type=ChunkType.TABLE,
                start_char=start_char,
                end_char=start_char + len(text),
                metadata={"is_table": True}
            )]
        
        # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ
        if len(text) <= self.config.chunk_size:
            chunk_type = ChunkType.TITLE if section_type == "title" else ChunkType.PARAGRAPH
            return [Chunk(
                text=text.strip(),
                index=start_index,
                chunk_type=chunk_type,
                start_char=start_char,
                end_char=start_char + len(text)
            )]
        
        # ë¬¸ì¥ ê¸°ë°˜ ë¶„í• 
        if self.config.sentence_boundary:
            return self._split_by_sentences(text, start_index, start_char)
        else:
            return self._split_by_size(text, start_index, start_char)
    
    def _split_by_sentences(
        self,
        text: str,
        start_index: int,
        start_char: int
    ) -> List[Chunk]:
        """ë¬¸ì¥ ê²½ê³„ ê¸°ë°˜ ë¶„í• """
        # ë¬¸ì¥ ë¶„ë¦¬
        sentences = self.sentence_endings.split(text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        chunks = []
        current_chunk = ""
        current_start = start_char
        chunk_index = start_index
        
        for sentence in sentences:
            # í˜„ì¬ ì²­í¬ + ìƒˆ ë¬¸ì¥ì´ ëª©í‘œ í¬ê¸° ì´í•˜ë©´ ì¶”ê°€
            if len(current_chunk) + len(sentence) <= self.config.chunk_size:
                current_chunk += sentence + " "
            else:
                # í˜„ì¬ ì²­í¬ ì €ì¥
                if current_chunk.strip():
                    chunks.append(Chunk(
                        text=current_chunk.strip(),
                        index=chunk_index,
                        chunk_type=ChunkType.PARAGRAPH,
                        start_char=current_start,
                        end_char=current_start + len(current_chunk)
                    ))
                    chunk_index += 1
                
                # ì˜¤ë²„ë© ì ìš©
                overlap_text = self._get_overlap_text(current_chunk)
                current_start = current_start + len(current_chunk) - len(overlap_text)
                current_chunk = overlap_text + sentence + " "
        
        # ë§ˆì§€ë§‰ ì²­í¬
        if current_chunk.strip():
            chunks.append(Chunk(
                text=current_chunk.strip(),
                index=chunk_index,
                chunk_type=ChunkType.PARAGRAPH,
                start_char=current_start,
                end_char=current_start + len(current_chunk)
            ))
        
        return chunks
    
    def _split_by_size(
        self,
        text: str,
        start_index: int,
        start_char: int
    ) -> List[Chunk]:
        """í¬ê¸° ê¸°ë°˜ ë¶„í•  (í´ë°±)"""
        chunks = []
        start = 0
        chunk_index = start_index
        
        while start < len(text):
            end = start + self.config.chunk_size
            
            # ë‹¨ì–´ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            if end < len(text):
                # ê³µë°± ìœ„ì¹˜ ì°¾ê¸°
                space_pos = text.rfind(' ', start + self.config.min_chunk_size, end)
                if space_pos > start:
                    end = space_pos
            
            chunk_text = text[start:end].strip()
            
            if chunk_text:
                chunks.append(Chunk(
                    text=chunk_text,
                    index=chunk_index,
                    chunk_type=ChunkType.PARAGRAPH,
                    start_char=start_char + start,
                    end_char=start_char + end
                ))
                chunk_index += 1
            
            # ì˜¤ë²„ë© ì ìš©
            start = end - self.config.chunk_overlap
        
        return chunks
    
    def _get_overlap_text(self, text: str) -> str:
        """ì˜¤ë²„ë© í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë¬¸ì¥ ê²½ê³„ ìœ ì§€)"""
        if len(text) <= self.config.chunk_overlap:
            return text
        
        overlap_start = len(text) - self.config.chunk_overlap
        
        # ë¬¸ì¥ ì‹œì‘ì  ì°¾ê¸°
        sentence_start = text.find('. ', overlap_start)
        if sentence_start > 0 and sentence_start < len(text) - 10:
            return text[sentence_start + 2:]
        
        # ê³µë°± ìœ„ì¹˜ ì°¾ê¸°
        space_pos = text.find(' ', overlap_start)
        if space_pos > 0:
            return text[space_pos + 1:]
        
        return text[overlap_start:]
    
    def _merge_small_chunks(self, chunks: List[Chunk]) -> List[Chunk]:
        """ì‘ì€ ì²­í¬ ë³‘í•©"""
        if not chunks:
            return chunks
        
        merged = []
        current = None
        
        for chunk in chunks:
            if current is None:
                current = chunk
                continue
            
            # í˜„ì¬ ì²­í¬ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ë‹¤ìŒê³¼ ë³‘í•©
            if current.length < self.config.min_chunk_size:
                # í…Œì´ë¸”ì€ ë³‘í•©í•˜ì§€ ì•ŠìŒ
                if current.chunk_type != ChunkType.TABLE and chunk.chunk_type != ChunkType.TABLE:
                    current.text = current.text + "\n\n" + chunk.text
                    current.end_char = chunk.end_char
                    continue
            
            merged.append(current)
            current = chunk
        
        if current:
            merged.append(current)
        
        return merged


# ============================================
# í¸ì˜ í•¨ìˆ˜
# ============================================

_default_chunker: Optional[SmartChunker] = None


def get_chunker(config: ChunkingConfig = None) -> SmartChunker:
    """ê¸°ë³¸ ì²­ì»¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _default_chunker
    if _default_chunker is None or config is not None:
        _default_chunker = SmartChunker(config)
    return _default_chunker


def chunk_text(text: str, document_id: str = "") -> List[Chunk]:
    """í…ìŠ¤íŠ¸ ì²­í‚¹ (í¸ì˜ í•¨ìˆ˜)"""
    return get_chunker().chunk(text, document_id)


def chunk_text_simple(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ ì²­í‚¹ (ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)"""
    chunks = get_chunker().chunk(text)
    return [c.text for c in chunks]


# ============================================
# í…ŒìŠ¤íŠ¸
# ============================================

if __name__ == "__main__":
    print("=" * 60)
    print("Smart Chunker í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    test_text = """
# 2025ë…„ë„ ì§€ë°©ì„¸ ë‚©ë¶€ ì•ˆë‚´

## 1. ê°œìš”
ë‚©ì„¸ì ì—¬ëŸ¬ë¶„ê»˜ 2025ë…„ë„ ì§€ë°©ì„¸ ë‚©ë¶€ì— ëŒ€í•´ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.
ì˜¬í•´ ì¬ì‚°ì„¸ëŠ” ì „ë…„ ëŒ€ë¹„ 5% ì¸ìƒë˜ì—ˆìŠµë‹ˆë‹¤.

## 2. ë‚©ë¶€ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| ì„¸ê¸ˆ ì¢…ë¥˜ | ì¬ì‚°ì„¸ |
| ë‚©ë¶€ ê¸ˆì•¡ | 250,000ì› |
| ë‚©ë¶€ ê¸°í•œ | 2025ë…„ 3ì›” 31ì¼ |

## 3. ë‚©ë¶€ ë°©ë²•
ê°€. ìœ„íƒìŠ¤ ì˜¨ë¼ì¸ ë‚©ë¶€ (www.wetax.go.kr)
ë‚˜. ì€í–‰ ë°©ë¬¸ ë‚©ë¶€
ë‹¤. ê°€ìƒê³„ì¢Œ ì´ì²´

## 4. ì£¼ì˜ì‚¬í•­
- ë‚©ë¶€ ê¸°í•œ ë‚´ ë¯¸ë‚© ì‹œ 3%ì˜ ê°€ì‚°ì„¸ê°€ ë¶€ê³¼ë©ë‹ˆë‹¤.
- ë¶„í•  ë‚©ë¶€ë¥¼ ì›í•˜ì‹œë©´ ì„¸ë¬´ê³¼ë¡œ ë¬¸ì˜í•˜ì„¸ìš”.
- ë¬¸ì˜: ì„¸ë¬´ê³¼ 02-1234-5678

ê°ì‚¬í•©ë‹ˆë‹¤.
"""
    
    chunker = SmartChunker(ChunkingConfig(
        chunk_size=500,
        chunk_overlap=100
    ))
    
    chunks = chunker.chunk(test_text, "test-doc")
    
    print(f"\nğŸ“Š ìƒì„±ëœ ì²­í¬: {len(chunks)}ê°œ\n")
    
    for i, chunk in enumerate(chunks):
        print(f"--- ì²­í¬ #{i} ({chunk.chunk_type.value}, {chunk.length}ì) ---")
        print(chunk.text[:150] + "..." if len(chunk.text) > 150 else chunk.text)
        print()